{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Animal_Re-ID_Classifier.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NGRotN_PpNyJ","colab_type":"text"},"source":["First we're going to load the necessary libraries for training out model"]},{"cell_type":"code","metadata":{"id":"5PLWOjMDoZIa","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import cv2\n","import time\n","import random\n","import matplotlib.pyplot as plt\n","from random import shuffle\n","from tqdm import tqdm\n","from imgaug import augmenters as iaa\n","from keras.models import Model, load_model\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, CSVLogger, LambdaCallback\n","\n","from keras.applications import MobileNetV2\n","from keras.applications.densenet import DenseNet201\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vsQckago2rU","colab_type":"text"},"source":["Next we're going to set which model we'll be training. This is up to you and your application. From our work we recommend DenseNet201 for accuracy, and MobileNetv2 for efficiency. Replace 'DenseNet201' with 'MobileNetV2' if you'd like to try it."]},{"cell_type":"code","metadata":{"id":"CrIpfXhmqS12","colab_type":"code","colab":{}},"source":["Network = 'DenseNet201'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tlHIaMY5qq-2","colab_type":"text"},"source":["We're going to set the default settings for the network"]},{"cell_type":"code","metadata":{"id":"ORdtZsOyo7Cg","colab_type":"code","colab":{}},"source":["TRAIN_DIR = 'Train/'\n","TEST_DIR = 'Test/'\n","IMG_SIZE = 224\n","epoch = 200\n","batch_size = 32\n","train_all_weights = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9Lf7PAdqyzu","colab_type":"text"},"source":["Now we're going to gather information about the data including: The number of images, the maximum number of a classification, the ratio balance, and store it in a dictionary"]},{"cell_type":"code","metadata":{"id":"9kh0xQslqyNK","colab_type":"code","outputId":"d7b057cd-fb26-439e-ac12-89dbb30d903a","executionInfo":{"status":"error","timestamp":1567964225324,"user_tz":240,"elapsed":644,"user":{"displayName":"Stefan Schneider","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBWP8FWwKBoYkDoMayKcxaH_ER7cCBgugG4XR7_VQ=s64","userId":"02896263219241037789"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["Class_List = os.listdir(TRAIN_DIR)\n","Num_Classes = len(Class_List)\n","\n","Num_Images_Dict, Num_Test_Images_Dict, ratio_dict = {}, {}, {}\n","\n","for animal in os.listdir(TRAIN_DIR): \n","  Num_Images_Dict[animal] = len(os.listdir(TRAIN_DIR + animal))\n","for animal in os.listdir(TEST_DIR): \n","  Num_Test_Images_Dict[animal] = len(os.listdir(TEST_DIR + animal))\n","\n","for classification in Num_Images_Dict:\n","  if Num_Images_Dict[classification] > maxbreak: Num_Images_Dict[classification] = maxbreak\n","\n","max_class_num = Num_Images_Dict[max(Num_Images_Dict, key=Num_Images_Dict.get)]\n","\n","for classification in Num_Images_Dict:\n","  ratio_dict[classification] = Num_Images_Dict[classification] / max_class_num\n"],"execution_count":31,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-c11cc53bf27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClass_List\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mNum_Classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClass_List\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNum_Images_Dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNum_Test_Images_Dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Train/'"]}]},{"cell_type":"markdown","metadata":{"id":"a-q3e5TY0V-b","colab_type":"text"},"source":["Here we define to image augmentation strategies. The first when building the data, the second when training."]},{"cell_type":"code","metadata":{"id":"-SxX8U6a0iS7","colab_type":"code","colab":{}},"source":["train_aug = iaa.SomeOf((1, 3), [  # Random number between 0, 3\n","    iaa.Fliplr(0.5),  # Horizontal flips                     \n","    iaa.Add((-5, 5)),  # Overall Brightness                   \n","    iaa.Multiply((0.95, 1.05), per_channel=0.2),  # Brightness multiplier per channel    0.05\n","    iaa.Sharpen(alpha=(0.1, 0.75), lightness=(0.85, 1.15)),  # Sharpness                            0.05\n","    iaa.WithColorspace(to_colorspace='HSV', from_colorspace='RGB',  # Random HSV increase                  0.09\n","                       children=iaa.WithChannels(0, iaa.Add((-30, 30)))),\n","    iaa.WithColorspace(to_colorspace='HSV', from_colorspace='RGB',\n","                       children=iaa.WithChannels(1, iaa.Add((-30, 30)))),\n","    iaa.WithColorspace(to_colorspace='HSV', from_colorspace='RGB',\n","                       children=iaa.WithChannels(2, iaa.Add((-30, 30)))),\n","    iaa.AddElementwise((-10, 10)),  # Per pixel addition                   0.11\n","    iaa.CoarseDropout((0.0, 0.02), size_percent=(0.02, 0.25)),  # Add large black squares              0.13\n","    iaa.GaussianBlur(sigma=(0.1, 1.0)),  # GaussianBlur                         0.14\n","    iaa.Grayscale(alpha=(0.1, 1.0)),  # Random Grayscale conversion          0.17\n","    iaa.Dropout(p=(0, 0.1), per_channel=0.2),  # Add small black squares              0.17\n","    iaa.AdditiveGaussianNoise(scale=(0.0, 0.05 * 255), per_channel=0.5),\n","    # Add Gaussian per pixel noise         0.26\n","    iaa.ElasticTransformation(alpha=(0, 1.0), sigma=0.25),  # Distort image by rearranging pixels  0.70\n","    iaa.ContrastNormalization((0.75, 1.5)),  # Contrast Normalization               0.95\n","    iaa.weather.Clouds(),\n","    iaa.weather.Fog(),\n","    iaa.weather.Snowflakes()], \n","    random_order=True)\n","\n","batch_aug = iaa.SomeOf((1, 2), [\n","  iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},  # Affine: Scale/zoom,                  \n","             translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},  # Translate/move\n","             rotate=(-90, 90), shear=(-4, 4)),  # Rotate and Shear\n","  iaa.PiecewiseAffine(scale=(0, 0.05)),],  # Distort Image similar water droplet  \n","  random_order=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcVFOYp_sBUj","colab_type":"text"},"source":["Next we're going to define a function building our training and testing data. This goes through each image, resizes them so they can fit on the GPU and returns a list of them all. It also provides augmentation and the described ratio prior distribution."]},{"cell_type":"code","metadata":{"id":"V4VRoqN6sUAp","colab_type":"code","colab":{}},"source":["def create_data(DATA_DIR, IMG_SIZE, Train):\n","    data, classnum = [], -1\n","    for animal in tqdm(os.listdir(DATA_DIR)[:5]):\n","        print('\\n', animal)\n","        classnum += 1\n","        i, imglist = 0, os.listdir(DATA_DIR + animal)\n","        shuffle(imglist)\n","        for i in range(len(imglist)-1):\n","            img = cv2.resize(cv2.imread(DATA_DIR + animal + '/' + imglist[i]), (IMG_SIZE, IMG_SIZE))\n","            zerolist = [0] * Num_Classes\n","            zerolist[classnum] += 1\n","            data.append([np.array(img), zerolist])\n","            if i >= maxbreak: break\n","            if Train == True:\n","                for k in range(max_class_num - len(imglist)):\n","                    aug_img = train_aug.augment_image(img)\n","                    zerolist = [0] * Num_Classes\n","                    zerolist[classnum] += 1\n","                    data.append([np.array(aug_img), zerolist])\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hp4D9E-sZtj","colab_type":"text"},"source":["Next we're going to create the data using the create_data function and convert it into our data and labels for our train and test sets. Since we have the data and labels isolated now, we can delete the collection of them to save memory"]},{"cell_type":"code","metadata":{"id":"qZarb2XisopZ","colab_type":"code","colab":{}},"source":["train_data = create_data(TRAIN_DIR, IMG_SIZE, Train=True)\n","test_data = create_data(TEST_DIR, IMG_SIZE, Train=False)\n","\n","print('Train Size: {}'.format(len(train_data)))\n","print('Test Size: {}'.format(len(test_data)))\n","\n","x_train = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n","y_train = np.array([i[1] for i in train_data])\n","\n","x_test = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n","y_test = np.array([i[1] for i in test_data])\n","\n","del train_data\n","del test_data\n","\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6L3wESGus_K2","colab_type":"text"},"source":["We're not going to write a simple text file that provides info of the training test distribution. We're going to write a simple plotting function to view our training and testing distribution. These should be as similar as possible. I also define a plotting metrics function for our results that we use later."]},{"cell_type":"code","metadata":{"id":"bH-a_1kAv5lB","colab_type":"code","colab":{}},"source":["def Write_Classifications():\n","    file = open('{}/{}/{}_Class_{}_saved_models/{}_{}_{}_Classes.txt'.format(Network, IMG_SIZE, Num_Classes, starttime,\n","                                                                          Num_Classes, IMG_SIZE, starttime), 'w')\n","    file.write('Classifications and Training Numbers:\\n\\n')\n","    for animal in Num_Images_Dict: file.write(str(animal) + ':' + str(Num_Images_Dict[animal]) + '\\n')\n","    file.write('\\n\\nClassifications and Testing Numbers:\\n\\n')\n","    for animal in Num_Test_Images_Dict: file.write(str(animal) + ':' + str(Num_Test_Images_Dict[animal]) + '\\n')\n","\n","\n","def Plot_Data_Distribution(image_dict, data_type):\n","    plt.title('{} Class Training Distribution'.format(Num_Classes))\n","    plt.ylabel('Num Images')\n","    plt.bar(image_dict.keys(), image_dict.values(), color='g')\n","    plt.xticks(rotation=90)\n","    plt.savefig('{}/{}/{}_Class_{}_saved_models/{}_Distribution.png'.format(Network, IMG_SIZE, Num_Classes,\n","                                                                            starttime, data_type))\n","\n","def plot_metrics(data1, data2, IMG_SIZE, metric):\n","    plt.plot(data1)\n","    plt.plot(data2)\n","    plt.title('History of Multiclass Animal Model {} During Training'.format(metric))\n","    plt.ylabel(metric)\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.savefig('{}/{}/{}_Class_{}_saved_models/{}_{}_{}_{}.png'.format(Network, IMG_SIZE, Num_Classes,\n","                                                            starttime, Num_Classes, IMG_SIZE, starttime, metric))\n","    plt.clf()\n","    \n","Write_Classifications()\n","Plot_Data_Distribution(Num_Images_Dict, 'Training')\n","Plot_Data_Distribution(Num_Test_Images_Dict, 'Testing')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIPgl7QAwY7Q","colab_type":"text"},"source":["Next we're going to load our network depending on if you selected 'DenseNet201' or 'MobileNetV2' previously. We're also going to print a summary of the network, select the optimizer Adam, and create a csv log of the training process. "]},{"cell_type":"code","metadata":{"id":"7OFXhpDzs85X","colab_type":"code","colab":{}},"source":["\n","shape = (IMG_SIZE, IMG_SIZE, 3)\n","if network == 'DenseNet201':\n","    base_model = DenseNet201(input_shape=shape, weights='imagenet', include_top=False)\n","elif network == 'MobileNetV2':\n","    base_model = MobileNetV2(input_shape=shape, weights='imagenet', include_top=False)\n","else:\n","    print('network name not either DenseNet201 or MobileNetV2')\n","x = base_model.output\n","x = GlobalAveragePooling2D(name='ex_Pool')(x)\n","x = Dense(1024, activation='relu', name='ex_Dense1', kernel_initializer='glorot_normal')(x)\n","x = Dense(1024, activation='relu', name='ex_Dense2', kernel_initializer='glorot_normal')(x)\n","x = Dense(512, activation='relu', name='ex_Dense3', kernel_initializer='glorot_normal')(x)\n","output = Dense(Num_Classes, activation='softmax', name='softmax')(x)\n","for layer in base_model.layers: \n","  layer.trainable = train_all_weights\n","model = Model(inputs=base_model.input, outputs=output)\n","model.summary()\n","model.compile(optimizer=Adam(lr=0.0001, decay=1e-6),\n","              loss={'softmax': 'categorical_crossentropy'},\n","              metrics={'softmax': 'accuracy'})\n","\n","csv_logger = CSVLogger('{}/{}/{}_Class_{}_saved_models/{}_{}_{}_Logger.csv'.format(Network, IMG_SIZE, Num_Classes,\n","                                                                starttime, Num_Classes, IMG_SIZE, starttime), separator=',')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_IGmQXnyksd","colab_type":"text"},"source":["Here we're going to define a generator, which allows us to modify the input images with augmentation and ratio prior for each epoch of training. "]},{"cell_type":"code","metadata":{"id":"HW0UFZb1yl8h","colab_type":"code","colab":{}},"source":["\n","\n","def generator(x_train, y_train, batch_size):\n","    batch_x_train = np.zeros((batch_size, IMG_SIZE, IMG_SIZE, 3))\n","    batch_y_train = np.zeros((batch_size, Num_Classes))\n","    index_dict = {}\n","    for i in range(len(x_train)):\n","        if y_train[i].argmax() not in index_dict: index_dict[y_train[i].argmax()] = [i]\n","        else: index_dict[y_train[i].argmax()].append(i)\n","\n","    while True:\n","        i = 0\n","        while i < batch_size - 1:\n","            index = np.random.randint(0, len(x_train) - 1)\n","            while True:\n","                if random.random() > ratio_dict[Class_List[y_train[index].argmax()]]:\n","                    random_index = random.choice(index_dict[y_train[index].argmax()])\n","                    batch_x_train[i] = batch_aug.augment_image(x_train[random_index])\n","                    batch_y_train[i] = y_train[random_index]\n","                    i += 1\n","                    if i == batch_size - 1: break\n","                else:\n","                    batch_x_train[i] = batch_aug.augment_image(x_train[index])\n","                    batch_y_train[i] = y_train[index]\n","                    break\n","            i += 1\n","        yield batch_x_train, batch_y_train"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvEzzVAZ01fS","colab_type":"text"},"source":["Finally now, we train the model! After the model has finished training (which can take a looong while, possibly days with a large enough dataset). We'll also plot our metrics."]},{"cell_type":"code","metadata":{"id":"W0Y28qeDs8-E","colab_type":"code","colab":{}},"source":["history = model.fit_generator(generator(x_train, y_train, batch_size),\n","                                  validation_data=(x_test, y_test),\n","                                  shuffle=True,\n","                                  steps_per_epoch=x_train.shape[0] / batch_size,\n","                                  epochs=epochs,\n","                                  callbacks=[csv_logger,\n","                                      ModelCheckpoint('%s/%s/%s_Class_%s_saved_models/weights.{epoch:02d}-'\n","                                                     '{val_acc:.2f}.hdf5' % (Network, IMG_SIZE, Num_Classes, starttime),\n","                                                      monitor='val_acc', verbose=0, save_best_only=True,\n","                                                      save_weights_only=False, mode='auto', period=1)])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cXEyCHIT1E1y","colab_type":"text"},"source":["And that's it! Hopefully this was helpful for training a model. "]}]}